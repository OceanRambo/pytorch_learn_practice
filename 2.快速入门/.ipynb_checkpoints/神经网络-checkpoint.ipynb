{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autograd实现了反向传播功能，但是直接用来写深度学习的代码在很多情况下还是稍显复杂，torch.nn是专门为神经网络设计的模块化接口。nn构建于 Autograd之上，可用来定义和运行神经网络。nn.Module是nn中最重要的类，可把它看成是一个网络的封装，包含网络各层定义以及forward方法，调用forward(input)方法，可返回前向传播的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义一个网络\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 卷积层 '1'表示输入图片为单通道, '6'表示输出通道数，'5'表示卷积核为5*5\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # 仿射层/全连接层，y = Wx + b\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "    # 卷积 -> 激活 -> 池化 \n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) \n",
    "        # reshape，‘-1’表示自适应\n",
    "        x = x.view(x.size()[0], -1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<generator object Module.parameters at 0x00000296A8E67E08>, 10)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = net.parameters()  # 网络的可学习参数\n",
    "params, len(list(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight : torch.Size([6, 1, 5, 5])\n",
      "conv1.bias : torch.Size([6])\n",
      "conv2.weight : torch.Size([16, 6, 5, 5])\n",
      "conv2.bias : torch.Size([16])\n",
      "fc1.weight : torch.Size([120, 400])\n",
      "fc1.bias : torch.Size([120])\n",
      "fc2.weight : torch.Size([84, 120])\n",
      "fc2.bias : torch.Size([84])\n",
      "fc3.weight : torch.Size([10, 84])\n",
      "fc3.bias : torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, parameters in net.named_parameters():   # net.named_parameters可同时返回可学习的参数及名称\n",
    "    print(name, ':', parameters.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0071,  0.0579,  0.0985,  0.0242,  0.0981, -0.0783,  0.0753,\n",
       "          0.1373, -0.0037, -0.0356]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 损失函数\n",
    "nn实现了神经网络中大多数的损失函数，例如nn.MSELoss用来计算均方误差，nn.CrossEntropyLoss用来计算交叉熵损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28.2272)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.arange(0,10).view(1,10) \n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(output, target)\n",
    "loss # loss是个scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "反向传播之前 conv1.bias的梯度\n",
      "None\n",
      "反向传播之后 conv1.bias的梯度\n",
      "tensor([ 0.0840, -0.1576,  0.0089,  0.0368,  0.0421, -0.0031])\n"
     ]
    }
   ],
   "source": [
    "# 运行.backward，观察调用之前和调用之后的grad\n",
    "net.zero_grad() # 把net中所有可学习参数的梯度清零\n",
    "print('反向传播之前 conv1.bias的梯度')\n",
    "print(net.conv1.bias.grad)\n",
    "loss.backward()\n",
    "print('反向传播之后 conv1.bias的梯度')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "#新建一个优化器，指定要调整的参数和学习率\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.01)\n",
    "\n",
    "# 在训练过程中\n",
    "# 先梯度清零(与net.zero_grad()效果一样)\n",
    "optimizer.zero_grad() \n",
    "\n",
    "# 计算损失\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "\n",
    "#反向传播\n",
    "loss.backward()\n",
    "\n",
    "#更新参数\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 实战：\n",
    "CIFAR-10分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                     (0.5, 0.5, 0.5))])\n",
    "\n",
    "# 下载数据集，若相应目录存在，通过root参数指定\n",
    "trainset = torchvision.datasets.CIFAR10(root='../../data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../../data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Dataset对象是一个数据集，可以按下标访问，返回形如(data, label)的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "torch.Size([3, 32, 32])\n",
      "frog\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=100x100 at 0x296A8F2B0B8>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show = ToPILImage() # 可以把Tensor转成Image，方便可视化\n",
    "(data, label) = trainset[0]   \n",
    "print(len(trainset))\n",
    "print(data.size())\n",
    "print(classes[label])\n",
    "\n",
    "# (data + 1) / 2是为了还原被归一化的数据\n",
    "show((data + 1) / 2).resize((100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 定义网络\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) \n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)  \n",
    "        self.fc1   = nn.Linear(16*5*5, 120)  \n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) \n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) \n",
    "        x = x.view(x.size()[0], -1)     # 等价 x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)        \n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # 交叉熵损失函数\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2000, loss: 21.7832\n",
      "1, 4000, loss: 19.0221\n",
      "1, 6000, loss: 16.9623\n",
      "1, 8000, loss: 15.9697\n",
      "1, 10000, loss: 15.1915\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outs = net(inputs)\n",
    "        loss = criterion(outs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()   # loss.data[0]\n",
    "        if (i+1) % 2000 == 0:\n",
    "            print('{}, {}, loss: {:.4f}'.format(epoch + 1, i + 1, running_loss/200))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next() # 一个batch返回4张图片\n",
    "print('实际的label: ', ' '.join(\\\n",
    "            '%08s'%classes[labels[j]] for j in range(4)))\n",
    "show(torchvision.utils.make_grid(images / 2 + 0.5)).resize((400,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算图片在每个类别上的分数\n",
    "outputs = net(images)\n",
    "# 得分最高的那个类\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "print('预测结果: ', ' '.join('%5s'\\\n",
    "            % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0 # 预测正确的图片数\n",
    "total = 0 # 总共的图片数\n",
    "\n",
    "\n",
    "# 由于测试的时候不需要求导，可以暂时关闭autograd，提高速度，节约内存\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "print('10000张测试集中的准确率为: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看每个类别的识别率\n",
    "# class_correct = list(0. for i in range(10))\n",
    "# class_total = list(0. for i in range(10))\n",
    "# for data in testloader:\n",
    "#     images, labels = data\n",
    "#     outputs = net(images)\n",
    "#     _, predicted = torch.max(outputs.data, 1)\n",
    "#     c = (predicted == labels).squeeze()\n",
    "#     for i in range(4):\n",
    "#         label = labels[i]\n",
    "#         class_correct[label] += c[i]\n",
    "#         class_total[label] += 1\n",
    "\n",
    "# for i in range(10):\n",
    "#     print('Accuracy of %5s : %2d %%' % (\n",
    "#         classes[i], 100 * class_correct[i].float() / class_total[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
