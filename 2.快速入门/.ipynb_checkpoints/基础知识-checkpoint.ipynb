{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pyTorch的基础知识"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor是pyTorch中的重要数据结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  1.2163e-42],\n",
       "        [ 0.0000e+00,  7.0065e-45,  0.0000e+00],\n",
       "        [-1.2196e+32,  6.9364e-43,  0.0000e+00],\n",
       "        [ 0.0000e+00,  7.0065e-45,  0.0000e+00],\n",
       "        [-1.2197e+32,  6.9364e-43,  0.0000e+00]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  构建 5x3 矩阵，只是分配了空间，未初始化\n",
    "x = torch.Tensor(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3518,  0.6970,  0.3894],\n",
       "        [ 0.9692,  0.4398,  0.0020],\n",
       "        [ 0.9747,  0.2134,  0.9630],\n",
       "        [ 0.6245,  0.9902,  0.2900],\n",
       "        [ 0.5637,  0.4301,  0.9979]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3]), torch.Size([5, 3]), 5, 3)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " x.size(), x.shape, x.size(0), x.size()[1]  # 查看x的形状，行，列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7773,  0.4528,  0.8945],\n",
       "        [ 0.0800,  0.0656,  0.4296],\n",
       "        [ 0.9672,  0.7910,  0.7132],\n",
       "        [ 0.8268,  0.9885,  0.0143],\n",
       "        [ 0.3792,  0.0680,  0.9367]])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1291,  1.1498,  1.2840],\n",
       "        [ 1.0492,  0.5053,  0.4317],\n",
       "        [ 1.9419,  1.0044,  1.6762],\n",
       "        [ 1.4513,  1.9787,  0.3043],\n",
       "        [ 0.9430,  0.4981,  1.9346]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加法的几种写法\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1291,  1.1498,  1.2840],\n",
       "        [ 1.0492,  0.5053,  0.4317],\n",
       "        [ 1.9419,  1.0044,  1.6762],\n",
       "        [ 1.4513,  1.9787,  0.3043],\n",
       "        [ 0.9430,  0.4981,  1.9346]])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1291,  1.1498,  1.2840],\n",
       "        [ 1.0492,  0.5053,  0.4317],\n",
       "        [ 1.9419,  1.0044,  1.6762],\n",
       "        [ 1.4513,  1.9787,  0.3043],\n",
       "        [ 0.9430,  0.4981,  1.9346]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = torch.Tensor()\n",
    "torch.add(x, y, out=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1291,  1.1498,  1.2840],\n",
       "        [ 1.0492,  0.5053,  0.4317],\n",
       "        [ 1.9419,  1.0044,  1.6762],\n",
       "        [ 1.4513,  1.9787,  0.3043],\n",
       "        [ 0.9430,  0.4981,  1.9346]])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1291,  1.1498,  1.2840],\n",
       "        [ 1.0492,  0.5053,  0.4317],\n",
       "        [ 1.9419,  1.0044,  1.6762],\n",
       "        [ 1.4513,  1.9787,  0.3043],\n",
       "        [ 0.9430,  0.4981,  1.9346]])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.add_(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1291,  1.1498,  1.2840],\n",
       "        [ 1.0492,  0.5053,  0.4317],\n",
       "        [ 1.9419,  1.0044,  1.6762],\n",
       "        [ 1.4513,  1.9787,  0.3043],\n",
       "        [ 0.9430,  0.4981,  1.9346]])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.copy_(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 注意，函数名后面带下划线_ 的函数会修改Tensor本身。例如，x.add_(y)和x.t_()会改变 x，但x.add(y)和x.t()返回一个新的Tensor， 而x不变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5998, -0.5036, -0.9585,  0.2111],\n",
       "        [ 0.5805, -0.0628,  0.3313, -1.2722],\n",
       "        [-0.2446,  0.1221,  0.0191,  1.0641],\n",
       "        [-1.7733,  0.4213,  1.2326, -0.3900]])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用torch.view对tensor进行变形， -1 表示自适应\n",
    "x = torch.randn(4,4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5998, -0.5036, -0.9585,  0.2111,  0.5805, -0.0628,  0.3313,\n",
       "        -1.2722, -0.2446,  0.1221,  0.0191,  1.0641, -1.7733,  0.4213,\n",
       "         1.2326, -0.3900])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= x.view(16)   \n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5998, -0.5036, -0.9585,  0.2111,  0.5805, -0.0628,  0.3313,\n",
       "         -1.2722],\n",
       "        [-0.2446,  0.1221,  0.0191,  1.0641, -1.7733,  0.4213,  1.2326,\n",
       "         -0.3900]])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1 = x.view(-1, 8)\n",
    "z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5998, -0.5036, -0.9585,  0.2111],\n",
       "        [ 0.5805, -0.0628,  0.3313, -1.2722],\n",
       "        [-0.2446,  0.1221,  0.0191,  1.0641],\n",
       "        [-1.7733,  0.4213,  1.2326, -0.3900]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2 = x.view(4, -1)\n",
    "z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5998, -0.5036, -0.9585,  0.2111,  0.5805, -0.0628,  0.3313,\n",
       "        -1.2722, -0.2446,  0.1221,  0.0191,  1.0641, -1.7733,  0.4213,\n",
       "         1.2326, -0.3900])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = x.view(-1)  # 等价于x.view(16) \n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Tensor和Numpy的数组之间的互操作非常容易且快速. Torch Tensor 和 NumPy 数组将会共享它们的实际的内存位置, 改变一个另一个也会跟着改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转换 Torch Tensor 数组为 Numpy\n",
    "a = torch.ones(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.], dtype=float32)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 转换 NumPy 数组为 Torch Tensor\n",
    "a = numpy.ones(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  1.,  1.,  1.,  1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.from_numpy(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.,  2.,  2.,  2.,  2.], dtype=torch.float64)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.add_(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.,  2.,  2.,  2.,  2.]),\n",
       " tensor([ 2.,  2.,  2.,  2.,  2.], dtype=torch.float64))"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b   # a和b 均改变"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 如果你想获取某一个元素的值，可以使用scalar.item。 直接tensor[idx]得到的还是一个tensor: 一个0-dim 的tensor，一般称为scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([2])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = tensor.item()\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  1.,  1.,  1.,  1.], device='cuda:0'),\n",
       " tensor([ 0.,  0.,  0.,  0.,  0.], device='cuda:0'),\n",
       " tensor([ 1.,  1.,  1.,  1.,  1.], device='cuda:0'))"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  在不支持CUDA的机器下，下一步还是在CPU上运行\n",
    "a = torch.ones(5)\n",
    "b = torch.zeros(5)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "a = a.to(device)\n",
    "b = b.to(device)\n",
    "c = a + b\n",
    "a, b, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### autograd: 自动微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  1.],\n",
       "        [ 1.,  1.]])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 为tensor设置 requires_grad 标识，代表着需要求导数\n",
    "a = torch.ones((2, 2), requires_grad=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.sum()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SumBackward0 at 0x1effefd30b8>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  1.],\n",
       "        [ 1.,  1.]])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 注意：grad在反向传播过程中是累加的(accumulated)，这意味着每一次运行反向传播，梯度都会累加之前的梯度，所以反向传播之前需把梯度清零。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  2.],\n",
       "        [ 2.,  2.]])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.backward()\n",
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.,  3.],\n",
       "        [ 3.,  3.]])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.backward()\n",
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.],\n",
       "        [ 0.,  0.]])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 以下划线结束的函数是inplace操作，会修改自身的值，就像add_\n",
    "a.grad.zero_()    # 梯度清零   等价于 a.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  1.],\n",
       "        [ 1.,  1.]])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.backward()\n",
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
